{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tDDLGAkf_iQ-"},"outputs":[],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18353,"status":"ok","timestamp":1700189080293,"user":{"displayName":"Kaushi Gihan","userId":"11214181140146971518"},"user_tz":-330},"id":"3ptZ35cw_lNC","outputId":"10dfa588-5a8c-4c8b-bc4f-c8aabf176ca7"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","nltk.download('punkt')\n","from dateutil.parser import parse\n","from datetime import datetime\n","import spacy\n","from spacy.matcher import PhraseMatcher\n","from spacy.matcher import Matcher\n","\n","\n","# load spacy model\n","#nlp = spacy.load('en_core_web_lg')\n","#nlp = spacy.load('en_core_web_md')\n","nlp = spacy.load('en_core_web_sm')\n"]},{"cell_type":"markdown","metadata":{"id":"q2BdglT7OFEl"},"source":["**Get the inputs in jason**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1700191664544,"user":{"displayName":"Kaushi Gihan","userId":"11214181140146971518"},"user_tz":-330},"id":"CeEZMwdgmm6Q","outputId":"edc2aef3-88c9-4fe2-ac54-4bb398093830"},"outputs":[{"name":"stdout","output_type":"stream","text":["kaushika gihan rupasinghe\n","['kaushika', 'gihan', 'rupasinghe']\n","k.g rupasinghe\n","kg rupasinghe\n","no- 233/9/1, jayamawatha rd,kudamaduwa, siddamulla,piliyandala,sri lanka\n","['233/9/1', 'jayamawatha', 'kudamaduwa', 'siddamulla', 'piliyandala']\n","['1995-10-16']\n"]}],"source":["#get the inputs in jason\n","\n","full_name=\"kaushika gihan Rupasinghe\"\n","name_inti=\"K.G Rupasinghe\"\n","address=\"No- 233/9/1, Jayamawatha rd,kudamaduwa, siddamulla,piliyandala,sri lanka\"\n","birth_day=\"1995/16/oct\"\n","\n","#create the basics ,before spacy model\n","unwanted_symbols=[\".\",\"-\",\",\",\"_\",\":-\",\":\",\";\",\"%\"]\n","unwanted_words=[\"no-\",\"no:\",\"no\",\".\",\",\",\"-\",\"_\",\":-\",\":\",\";\",\"%\",\"mawatha\",\"mawata\",\"mavatha\",\"mawata\",\"mv\",\"mw\",\"sri lanka\",\"sri\",\n","                \"lanka\",\"para\",\"road\",\"rd\",\"no:-\",\"no;-\",\"no;\",'handiya',\"handhiya\"]\n","\n","#split full name\n","full_name=full_name.lower()\n","split_name=full_name.split(\" \")\n","\n","\n","#remove unwanted symbols\n","name_inti=name_inti.lower()\n","cleaned_name=\"\"\n","for char in name_inti:\n","    if char not in unwanted_symbols:\n","        cleaned_name += char\n","\n","#address\n","address=address.lower()\n","\n","#token address\n","token_addres = nltk.word_tokenize(address)\n","#print (token_addres)\n","\n","#remove unwanted words\n","address_split=[]\n","for word in token_addres:\n","  if word not in unwanted_words:\n","    address_split.append(word)\n","\n","#date format changing\n","birth_day=birth_day.lower()\n","YMD=[]\n","#from dateutil.parser import parse\n","def convert_to_YMD(date_string):\n","    try:\n","        # Parse the date string using dateutil\n","        parsed_date = parse(date_string)\n","\n","        # Convert it to Y-M-D format\n","        YMD_date = parsed_date.strftime(\"%Y-%m-%d\")\n","\n","        return YMD_date\n","    except ValueError:\n","        return None\n","\n","# Test with different date formats\n","date_strings = [birth_day]\n","\n","for date_string in date_strings:\n","    converted_date = convert_to_YMD(date_string)\n","    if converted_date:\n","        YMD.append(converted_date)\n","    else:\n","        print(f\"Date: {date_string} has an incorrect format.\")\n","\n","print(full_name)\n","print(split_name)\n","print(name_inti)\n","print(cleaned_name)\n","print(address)\n","print(address_split)\n","print(YMD)\n","#print(new_date_format)\n"]},{"cell_type":"markdown","metadata":{"id":"ayJSMTGFN65a"},"source":["Get the text from keras & easy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NG2jGSq6Mzy8"},"outputs":[],"source":["text_easyorc=\" 1975/10/16 age - 27 kaushika gihan rupasinghe ,1995/10/16, , k.g rupasinghe CEYLINCO GENERAL INSURANCE VP 'Ceylinco House' 69, Janadhipathi LTDeek Outhe Jert Mawatta; Coombo 1 Certificate of Insurance Vehicie No WPGJ8644 MCCLH229046371 Make & Vodel YavAHA DT125 Policy %o Pp00213F0008569 Name M.K.G. RUPASINGHE. Address No : 233/9/1 JAYA Mw KUDAMADUWA SIDDAMULLA Period of Cover 16-MAR-2023 To 16-MAR-2024 Engine No 3FW024477 Chassis No 2FW024477 16MAR Subjedtto terrns and conditions specifed in tne policy docurrient\"\n","text_kerasocr=\"cetlinc ceylinco general age 28 insurance lidnud vip ceylinco house 69 janadhipath manatha coombol ount sran certificate of insurance vehicle no wipgj8644 mcclhez6as71 make g wodel yamaha dt125 policy no ppoo21f066 name mra kg rupasinghe address 233191 no jaya mw kudamaduwa siddamulla 1gmar2023 15mar2024 period to cover of bfwo24477 engine no ismar 2fwo24477 chassis no docurnent the policy spected in conditons subjea and termns to\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJMrBubpNrff"},"outputs":[],"source":["text_easyorc=text_easyorc.lower()\n","text_kerasocr=text_kerasocr.lower()\n","\n","text=text_kerasocr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NPBsrSzsOJW5"},"outputs":[],"source":["print(text_easyorc)"]},{"cell_type":"markdown","metadata":{"id":"N3iIPddkqI3x"},"source":["**Spacy Matches**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12801,"status":"ok","timestamp":1700504507668,"user":{"displayName":"Kaushi Gihan","userId":"11214181140146971518"},"user_tz":-330},"id":"2wJrz73-T3zJ"},"outputs":[],"source":["#import library\n","import spacy\n","from spacy.matcher import PhraseMatcher\n","# load spacy model\n","#nlp = spacy.load('en_core_web_lg')\n","#nlp = spacy.load('en_core_web_md')\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1019,"status":"ok","timestamp":1700504912354,"user":{"displayName":"Kaushi Gihan","userId":"11214181140146971518"},"user_tz":-330},"id":"aZPu0odR9i0p"},"outputs":[],"source":["\n","# Save the spacy to the specified path\n","nlp.to_disk('Spacy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fO08rZR3OJay"},"outputs":[],"source":["def scoring_fun(full_name,split_name,name_inti,cleaned_name,address,address_split,YMD,text):\n","    #return variable\n","    name_final=[]\n","    address_final=[]\n","    age_final=[]\n","\n","######################full string matched function#####################\n","    #match the full string of the variation name and address\n","    def full_match(text,variation):\n","      score=0\n","      l=[]\n","\n","      #create matched items to need\n","      matcher = PhraseMatcher(nlp.vocab)\n","      #create matched items to need\n","      lang_list=[variation]\n","\n","      #create the pattern list\n","      # Only run nlp.make_doc to speed things up\n","      patterns = [nlp(lang) for lang in lang_list]\n","\n","      #add pattern to the matche\n","      matcher.add(\"TerminologyList\", patterns)\n","\n","      doc=nlp(text)\n","      matches=matcher(doc)\n","      #matched text append to l\n","\n","      for matcher_id,start,end in matches:\n","        span=doc[start:end]\n","        #print(span.text)\n","        l.append(span.text)\n","\n","      #remove repeate eliment\n","      l=list(set(l))\n","      #print(l)\n","\n","      #matched 100% ok with variation\n","      for i in l:\n","        for j in lang_list:\n","          if i==j:\n","            #print(100)\n","            score=100\n","          else:\n","            print(\"no 100% mathced with variable\")\n","\n","      if score== 100:\n","        return score\n","\n","      else:\n","        return 0\n","\n","################## split string mached function ###################\n","    def split_match(text,variation):\n","      l=[]\n","      #create matched items to need\n","      matcher = PhraseMatcher(nlp.vocab)\n","      lang_list=variation\n","\n","      # Only run nlp.make_doc to speed things up\n","      patterns = [nlp(lang) for lang in lang_list]\n","      matcher.add(\"TerminologyList\", patterns)\n","\n","      doc = nlp(text)\n","      matches = matcher(doc)\n","\n","      for match_id, start, end in matches:\n","        span = doc[start:end]\n","        #print(span.text)\n","        l.append(span.text)\n","\n","      #print(l)\n","\n","      l=list(set(l))\n","      #print(l)\n","\n","      matched_list=[]\n","      #percentage_score=0\n","      for i in l:\n","        for j in lang_list:\n","          if i==j:\n","            matched_list.append(i)\n","\n","      #print(matched_list)\n","\n","      percentage_score=len(matched_list)/len(lang_list)*100\n","      #print(percentage_score)\n","      return percentage_score\n","\n","############################ AGE ################\n","    def age(YMD,text):\n","      #final birthday score list\n","      birth_day_score=[]\n","\n","      #get the date in text\n","      # load spacy model\n","      #nlp = spacy.load('en_core_web_lg')\n","      #nlp = spacy.load('en_core_web_md')\n","      nlp = spacy.load('en_core_web_sm')\n","\n","      # load data\n","      sentence = text\n","      doc = nlp(sentence)\n","      date=[]\n","\n","      # print entities\n","      for ent in doc.ents:\n","        if ent.label_==\"DATE\":\n","          #print(ent.label_,ent.text)\n","          date.append(ent.text)\n","\n","        elif ent.label_==\"CARDINAL\":\n","          #print(ent.label_,ent.text)\n","          date.append(ent.text)\n","\n","      print(date)\n","      #Match the text date and YMD\n","      text_YMD=[]\n","\n","      #from dateutil.parser import parse\n","      def convert_to_YMD(date_string):\n","        try:\n","          # Parse the date string using dateutil\n","          parsed_date = parse(date_string)\n","\n","          # Convert it to Y-M-D format\n","          YMD_date = parsed_date.strftime(\"%Y-%m-%d\")\n","\n","          return YMD_date\n","        except ValueError:\n","          return None\n","\n","      # Test with different date formats\n","      date_strings = date\n","\n","      for date_string in date_strings:\n","        converted_date = convert_to_YMD(date_string)\n","        if converted_date:\n","            text_YMD.append(converted_date)\n","        else:\n","            print(f\"Date: {date_string} has an incorrect format.\")\n","\n","      print(text_YMD)\n","\n","      for dt in text_YMD:\n","        for sd in YMD:\n","          if dt == sd:\n","            birth_day_score.append(100)\n","\n","          else:\n","            birth_day_score.append(0)\n","\n","      ###check tha birth day in text\n","      l=[]\n","      #create matched items to need\n","      matcher = PhraseMatcher(nlp.vocab)\n","      lang_list=YMD\n","\n","      # Only run nlp.make_doc to speed things up\n","      patterns = [nlp(lang) for lang in lang_list]\n","      matcher.add(\"TerminologyList\", patterns)\n","\n","      doc = nlp(text)\n","      matches = matcher(doc)\n","\n","      for match_id, start, end in matches:\n","        span = doc[start:end]\n","        #print(span.text)\n","        l.append(span.text)\n","\n","      #print(l)\n","      l=list(set(l))\n","      #print(l)\n","\n","      for i in l:\n","        for j in lang_list:\n","          if i==j:\n","            birth_day_score.append(100)\n","          else:\n","            birth_day_score.append(0)\n","\n","      ###search age in text\n","      #from datetime import datetime\n","      #from spacy.matcher import Matcher\n","\n","      # Assuming the date of birth in the format \"YYYY-MM-DD\"\n","      date_of_birth = \" \"\n","      for b in YMD:\n","        date_of_birth=b\n","\n","      # Parse the date of birth string into a datetime object\n","      dob = datetime.strptime(date_of_birth, \"%Y-%m-%d\")\n","\n","      # Get the current date\n","      current_date = datetime.now()\n","\n","      # Calculate the age\n","      age = current_date.year - dob.year - ((current_date.month, current_date.day) < (dob.month, dob.day))\n","      #print(age)\n","\n","      ###check the age in text\n","\n","      matcher = Matcher(nlp.vocab)\n","      pattern = [{\"LOWER\": \"age\"}, {\"IS_PUNCT\": True}, {\"IS_DIGIT\": True}]\n","      matcher.add(\"Test\", [pattern])\n","      doc = nlp(text)\n","      matches = matcher(doc)\n","\n","      age_text=\"\"\n","      for matcher_id,start,end in matches:\n","        #print(doc[start:end])\n","        age_text=doc[start:end]\n","        #print(age_text)\n","\n","      final_age=\"\"\n","      tokens_age = nltk.word_tokenize(str(age_text))\n","      for q in tokens_age:\n","        if q==str(age):\n","          birth_day_score.append(100)\n","        else:\n","          birth_day_score.append(0)\n","\n","      ###Birthday final score\n","      final_B_score=0\n","      for s in birth_day_score:\n","        if s==100:\n","          final_B_score=s\n","          break\n","\n","        else:\n","          final_B_score=0\n","\n","      print(birth_day_score)\n","      #return age final score\n","      return final_B_score\n","\n","\n","#@@@@@@@@@@@@@@@@@@@@@@ method compile and get final scores @@@@@@@@@@@@@@@@@@@@@@#\n","\n","    full_name_score=full_match(text,full_name)\n","    name_inti_score=full_match(text,name_inti)\n","    cleaned_name_score=full_match(text,cleaned_name)\n","    split_name_score=split_match(text,split_name)\n","\n","    address_score=full_match(text,address)\n","    address_split_score=split_match(text,address_split)\n","\n","    age_score=age(YMD,text)\n","\n","    #name return final score\n","    name_final.append(full_name_score)\n","    name_final.append(name_inti_score)\n","    name_final.append(cleaned_name_score)\n","    name_final.append(split_name_score)\n","\n","    #name address final score\n","    address_final.append(address_score)\n","    address_final.append(address_split_score)\n","\n","    #age address final score\n","    age_final.append(age_score)\n","\n","    return  max(name_final),max(address_final),max( age_final)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2360,"status":"ok","timestamp":1698727627477,"user":{"displayName":"KAUSHI GIHAN","userId":"17781977202246029874"},"user_tz":-330},"id":"vKZzwzoJMz4m","outputId":"d2fbeed5-869f-4905-bc60-c02b9a8ee72f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['1975/10/16 age - 27', '1995/10/16', '69', '1', '233/9/1', '16-mar-2023', '16-mar-2024']\n","Date: 1975/10/16 age - 27 has an incorrect format.\n","['1995-10-16', '2069-10-31', '2023-10-01', '233-09-01', '2023-03-16', '2024-03-16']\n","[100, 0, 0, 0, 0, 0, 0, 0, 0]\n","['age 28', '69', '233191', '2fwo24477']\n","Date: age 28 has an incorrect format.\n","Date: 233191 has an incorrect format.\n","Date: 2fwo24477 has an incorrect format.\n","['2069-10-31']\n","[0]\n"]}],"source":["ocr_name,ocr_address,ocr_age=scoring_fun(full_name,split_name,name_inti,cleaned_name,address,address_split,YMD,text_easyorc)\n","keras_name,keras_address,keras_age=scoring_fun(full_name,split_name,name_inti,cleaned_name,address,address_split,YMD,text_kerasocr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":692,"status":"ok","timestamp":1698727646757,"user":{"displayName":"KAUSHI GIHAN","userId":"17781977202246029874"},"user_tz":-330},"id":"M_lykC66vfi2","outputId":"fc584206-0ac4-4850-9eda-c80f44daf00a"},"outputs":[{"name":"stdout","output_type":"stream","text":["100\n","60.0\n","100\n","100\n","40.0\n","0\n"]}],"source":["print(ocr_name)\n","print(ocr_address)\n","print(ocr_age)\n","\n","print(keras_name)\n","print(keras_address)\n","print(keras_age)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.8 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.8"},"vscode":{"interpreter":{"hash":"b337b16e1f284c9fe7de692799556d56c1809887abe3f5a49ffeb9e7df151cfb"}}},"nbformat":4,"nbformat_minor":0}
